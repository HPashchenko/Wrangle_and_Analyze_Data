{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target of this project is to put in practice what I learning during the section Data Wrangling.\n",
    "This Wrangle and Analyze Project is part of Udacity's Data Analyst Program. The dataset that is wrangles (analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. \n",
    "In this project I was working with the data wrangling, which consists of:\n",
    " - Gathering data, download resourses from diferent references\n",
    " - Assessing data, for quality and tidyness issues\n",
    " - Cleaning data, that identified in previous step\n",
    " - Storing, analyzing, and visualizig wrangled data\n",
    " - Reporting on data analyses and visualizations\n",
    " \n",
    "The most tools, libraries and programming language I used in this project are:\n",
    " - Python\n",
    " - Numpy Library\n",
    " - Pandas Library\n",
    " - Requests Library\n",
    " - Tweepy Library\n",
    " - Json Library\n",
    " - Matplotlib Notebook\n",
    " - Twitter's APi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was gathered from 3 different sources:\n",
    "1. The 'twitter-archive-enhanced' was provided by Udacity. This file includes a huge variety variables foe each tweet as tweet_id, timestamp, text, name, rating, ect.\n",
    "2. The 'image_prediction file was downloaded using the Requests library. \n",
    "3. Additional data, including favorite count and retweet count were gathered using the Twitter API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data\n",
    "After gathering data were used the following methods:\n",
    " - .head()\n",
    " - .sample()\n",
    " - .info()\n",
    " - .value_counts()\n",
    " \n",
    "Quality issue:\n",
    " - Tweet_id was the incirrect data type\n",
    " - The columns conteined the 'None' insted of 'NaN'\n",
    " - Timestamp was the incorrect datatype\n",
    " - Missing values from images datased(2075 rows insted of 2356)\n",
    " - Sources are not readable \n",
    " \n",
    "Tidiness issues:\n",
    " - Dogstage was in 4 columns(doggo, floofer, pupper, puppo), there is no reason to keep them\n",
    " - Merge all dataframes togethr as they all contained the proper information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the data wrangling was performed in three stages: Define, Code and Test. First, copies of DataFrames were created before cleaning. First and very helpful step for me was to create a copy of three original dataframes. \n",
    "Then used methods for investigation: merge(), reduce(), drop(), replace(), head(), etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing\n",
    "The final datset was stored as 'twitter_archive_final' in a csv file. At this step, the data was successfully wrangled and therefore ready for analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization \n",
    "In preparation for the analysis part, these three tables(datasets) needed to be put in relationship with each other. In my case the key element in each dataset is the tweet ID. Since I decided to run the analyzis usung Python Pandas library, the easiest wasy to set up the relationship, was to combine all datasets to one major table. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
