{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Wrangle and Analyze Project is part of Udacity's Data Analyst Program.\n",
    "In this project the dats wrangling, which consists of:\n",
    " - Gathering data, download resourses from diferent references\n",
    " - Assessing data, for quality and tidyness issues\n",
    " - Cleaning data, that identified in previous step\n",
    " - Storing, analyzing, and visualizig wrangled data\n",
    " - Reporting on data analyses and visualizations\n",
    " \n",
    "The most tools, libraries and programming language  used in this project are:\n",
    " - Python\n",
    " - Numpy Library\n",
    " - Pandas Library\n",
    " - Requests Library\n",
    " - Tweepy Library\n",
    " - Json Library\n",
    " - Matplotlib Notebook\n",
    " - Twitter's APi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was gathered from 3 different sources:\n",
    "1. The 'twitter-archive-enhanced' was provided by Udacity. This file includes a huge variety variables foe each tweet as tweet_id, timestamp, text, name, rating, ect.\n",
    "2. The 'image_prediction file was downloaded using the Requests library. \n",
    "3. Additional data, including favorite count and retweet count were gathered using the Twitter API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data\n",
    "After gathering data were used the following methods:\n",
    " - .head()\n",
    " - .sample()\n",
    " - .info()\n",
    " - .value_counts()\n",
    " \n",
    "Quality issue:\n",
    " - Tweet_id was the incirrect data type\n",
    " - The columns conteined the 'None' insted of 'NaN'\n",
    " - Timestamp was the incorrect datatype\n",
    " - Missing values from images datased(2075 rows insted of 2356)\n",
    " - Sources are not readable \n",
    " \n",
    "Tidiness:\n",
    " - Dogstage was in 4 columns(doggo, floofer, pupper, puppo), there is no reason to keep them\n",
    " - Merge all dataframes togethr as they all contained the proper information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the data wrangling was performed in three stages: Define, Code and Test. First, copies of DataFrames were created before cleaning. Then used methods for investigation: merge(), reduce(), drop(), replace(), head(), etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing\n",
    "The final datset was stored as 'twitter_archive_final' in a csv file. At this step, the data was successfully wrangled and therefore ready for analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization \n",
    "Visualizations are provided in act_report.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
